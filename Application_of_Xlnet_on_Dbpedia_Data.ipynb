{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Application of Xlnet on Dbpedia Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam131112/Core2vec_test/blob/master/Application_of_Xlnet_on_Dbpedia_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxHN3HIggOol",
        "colab_type": "text"
      },
      "source": [
        "### In this Notebook I use XLNET model on Dbpedia Topic classification dataset (https://www.kaggle.com/danofer/dbpedia-classes) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v8ojg_lon1d",
        "outputId": "ac2a1f4d-f1e6-41a2-e784-1dd68ea91bab",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/kaggle/input/dbpedia-classes/DBPEDIA_train.csv\n",
            "/kaggle/input/dbpedia-classes/DBPEDIA_test.csv\n",
            "/kaggle/input/dbpedia-classes/DBPEDIA_val.csv\n",
            "/kaggle/input/dbpedia-classes/DBP_wiki_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkM2q_PDo_2R",
        "outputId": "3d45dd04-c491-404d-b6aa-8c393a395f7d",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,WeightedRandomSampler\n",
        "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig,XLNetForSequenceClassification\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VK0Ie7exqeT",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score,accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LZD-6Oep3c_",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "234H4-7dN8tc",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/kaggle/input/dbpedia-classes/DBP_wiki_data.csv\")\n",
        "#train = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dbpedia-classes/DBPEDIA_train.csv\")\n",
        "#validation = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dbpedia-classes/DBPEDIA_val.csv\")\n",
        "#test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/dbpedia-classes/DBPEDIA_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUu5eKTIv-2t",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(data[\"l1\"])\n",
        "data[\"target\"] = le.transform(data['l1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tui6RGeFu4QU",
        "outputId": "4bccd6e7-f23d-44f9-c5a7-3ab7f4659d40",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHExeRyL0xve",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train , test = train_test_split(data,test_size=0.25,shuffle=True,random_state=42,stratify=data[\"target\"])\n",
        "train , val = train_test_split(train,test_size=0.1,shuffle=True,random_state=42,stratify=train[\"target\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNQV8nEs6m_c",
        "outputId": "9a320871-83ea-4763-fa3a-f2263077652b",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train),len(test),len(val))\n",
        "print(\"Train \",Counter(train['target']))\n",
        "print(\"Test \",Counter(test['target']))\n",
        "print(\"Validation \",Counter(val['target']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "231376 85696 25709\n",
            "Train  Counter({0: 119704, 3: 43961, 4: 21026, 8: 20137, 2: 18265, 5: 5607, 7: 1686, 6: 752, 1: 238})\n",
            "Test  Counter({0: 44336, 3: 16282, 4: 7787, 8: 7458, 2: 6765, 5: 2077, 7: 624, 6: 279, 1: 88})\n",
            "Validation  Counter({0: 13301, 3: 4885, 4: 2336, 8: 2237, 2: 2029, 5: 623, 7: 187, 6: 84, 1: 27})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETUebMDPkQQb",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hEgwh-kra2",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#config = XLNetConfig()\n",
        "#config.from_pretrained = 'xlnet-large-cased'\n",
        "#config.output_hidden_states = True\n",
        "#config.output_attentions = False\n",
        "#config.summary_type = 'mean'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T6tTi8jG-vX",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
        "#model = XLNetForSequenceClassification(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAhAruqvHDIK",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE5NWTikOhnH",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input_ids = tokenizer.encode_plus(\"Hello, my dog is cute\", add_special_tokens=True) # Batch size 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ZWohgUOomL",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input_ids , atten_mask , token_type_ids, labels  = torch.tensor(Input_ids[\"input_ids\"]).unsqueeze(0), torch.tensor(Input_ids[\"attention_mask\"]).unsqueeze(0),torch.tensor(Input_ids[\"token_type_ids\"]).unsqueeze(0),torch.tensor([1]).unsqueeze(0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysgSfxG9FtMY",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#outputs = model(input_ids=input_ids,attention_mask=atten_mask,token_type_ids=token_type_ids,labels=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvIjOFTzqOrc",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNiu-xnXmPh4",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#outputs[2][0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsL8pfp8hBb7",
        "colab_type": "text"
      },
      "source": [
        "# Starting Model Building From Here !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBOf_Aixhp3Z",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CreateData(tokenizer,data):\n",
        "    inp_ids = []\n",
        "    tok_type_ids = []\n",
        "    atten_mask  = []\n",
        "    labels = []\n",
        "    for i in range(len(data)):\n",
        "      text = data.iloc[i][\"text\"]\n",
        "      temp = tokenizer.encode_plus(text,max_length=100,pad_to_max_length = True)\n",
        "      inp_ids.append(temp[\"input_ids\"])\n",
        "      tok_type_ids.append(temp[\"token_type_ids\"])\n",
        "      atten_mask.append(temp[\"attention_mask\"])\n",
        "      labels.append([data.iloc[i][\"target\"]])\n",
        "    \n",
        "    input_ids = torch.tensor(inp_ids,dtype=torch.long)\n",
        "    attention_mask = torch.tensor(atten_mask,dtype=torch.long)\n",
        "    token_type_ids = torch.tensor(tok_type_ids,dtype=torch.long)\n",
        "    labels = torch.tensor(labels,dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_mask,token_type_ids,labels)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk1QyxmR1Fds",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_weight(data):\n",
        "  #data = data.copy()\n",
        "  counter = Counter(data[\"target\"].values)\n",
        "  print(counter)\n",
        "  data[\"Weight\"] = data[\"target\"].apply(lambda x:counter[x])\n",
        "  data[\"Weight\"] = 1.0 / data[\"Weight\"]\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72UQH6Xl5Za5",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_v = make_weight(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9D86JsTNhtf",
        "colab_type": "text"
      },
      "source": [
        "## Model Building with Dev Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqxSPXntOgH",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_engine(train_data,val_data,model,batch_sz,lr,epochs,device):\n",
        "\n",
        "  tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "  train_data = make_weight(train_data)\n",
        "  train_dataset = CreateData(tokenizer,train_data)\n",
        "  val_dataset = CreateData(tokenizer,val_data)\n",
        "  #pickle.dump(open(\"/content/drive/My Drive/Colab Notebooks/train_dataset_tokenised.p\",train_dataset))\n",
        "  #pickle.dump(open(\"/content/drive/My Drive/Colab Notebooks/val_dataset_tokenised.p\",val_dataset))\n",
        "  optimizer = AdamW(model.parameters(), lr=lr, weight_decay=1e-1, correct_bias=False)\n",
        "  #scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)\n",
        "  weight_sampler = WeightedRandomSampler(weights=train_data[\"Weight\"].values,num_samples=len(train_data[\"Weight\"].values),replacement=True)\n",
        "  train_loader = DataLoader(train_dataset,batch_size=batch_sz,sampler=weight_sampler)\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  best_loss = math.inf\n",
        "  for epoch in range(epochs):\n",
        "    epoch_train_loss = 0\n",
        "    model.train()\n",
        "    for batch_id,batch in enumerate(train_loader):\n",
        "      if batch_id % 7000 == 0:\n",
        "          print(epoch,batch_id)\n",
        "      optimizer.zero_grad()\n",
        "      inputs = {\"input_ids\": batch[0].to(device), \"attention_mask\": batch[1].to(device),  \"token_type_ids\": batch[2].to(device),\"labels\": batch[3].to(device)}\n",
        "      #lb = inputs[\"labels\"].squeeze(1).numpy().tolist()\n",
        "      #print(Counter(lb),len(Counter(lb)))\n",
        "      loss , logits = model(input_ids=inputs['input_ids'],attention_mask=inputs['attention_mask'],token_type_ids=inputs['token_type_ids'],labels=inputs['labels'])\n",
        "      _ , out_preds = torch.max(logits,axis=1)\n",
        "      epoch_train_loss = epoch_train_loss + loss.item()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    epoch_train_loss = epoch_train_loss / (1.0 * len(train_loader))\n",
        "    train_loss.append(epoch_train_loss)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      y_true_val = []\n",
        "      y_pred_val = []\n",
        "      epoch_val_loss = 0.0\n",
        "      epoch_val_acc = 0.0 \n",
        "      val_loader = DataLoader(val_dataset,batch_size=32)\n",
        "      for batch_id,batch in enumerate(val_loader):\n",
        "        inputs = {\"input_ids\": batch[0].to(device), \"attention_mask\": batch[1].to(device),  \"token_type_ids\": batch[2].to(device),\"labels\": batch[3].to(device)}\n",
        "        loss , logits = model(input_ids=inputs['input_ids'],attention_mask=inputs['attention_mask'],token_type_ids=inputs['token_type_ids'],labels=inputs['labels'])\n",
        "        epoch_val_loss = epoch_val_loss + loss.item()\n",
        "        _ , out_preds = torch.max(logits,axis=1)\n",
        "        epoch_val_acc =  epoch_val_acc + torch.eq(out_preds,inputs['labels'].squeeze(1)).sum().item()\n",
        "        #print(\"Validation id \",batch_id,batch[3].size(),torch.eq(out_preds,inputs['labels']).sum().item())\n",
        "        y_pred_val.extend(out_preds.detach().cpu().numpy().tolist())\n",
        "        y_true_val.extend(inputs[\"labels\"].squeeze(1).detach().cpu().numpy().tolist())\n",
        "\n",
        "      epoch_val_loss = epoch_val_loss / (len(val_loader)*1.0)\n",
        "      epoch_val_acc = epoch_val_acc / len(val_data)\n",
        "      val_loss.append(epoch_val_loss)\n",
        "      if best_loss > epoch_val_loss :\n",
        "        best_loss = epoch_val_loss\n",
        "        torch.save({\n",
        "                'model_state_dict':model.state_dict(),\n",
        "                'optimizer_state_dict':optimizer.state_dict(),\n",
        "                'loss':best_loss,},'/kaggle/saved_modelv1.pth')\n",
        "        \n",
        "    target_name = list(le.classes_)\n",
        "    print(\"*****************************************************************\")\n",
        "    print(\"Validation Report\")\n",
        "    print(\"*****************************************************************\")\n",
        "    print(classification_report(y_true_val,y_pred_val,target_names=target_name))\n",
        "    print(\"*****************************************************************\")\n",
        "  \n",
        "    print(epoch,train_loss[-1],val_loss[-1],epoch_val_acc,f1_score(y_true_val,y_pred_val,average='weighted'),accuracy_score(y_true_val,y_pred_val))  \n",
        "        \n",
        "  return model          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3855n2aVNcRf",
        "colab_type": "text"
      },
      "source": [
        "## Tester Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7tb4oap-GmT",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_engine(model,test_data):\n",
        "  tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "  preds_all = []\n",
        "  true_all = []\n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0 \n",
        "  test_dataset = CreateData(tokenizer,test_data)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      test_loader = DataLoader(test_dataset,batch_size=32)\n",
        "      for batch_id,batch in enumerate(test_loader):\n",
        "        inputs = {\"input_ids\": batch[0].to(device), \"attention_mask\": batch[1].to(device),  \"token_type_ids\": batch[2].to(device),\"labels\": batch[3].to(device)}\n",
        "        loss , logits = model(input_ids=inputs['input_ids'],attention_mask=inputs['attention_mask'],token_type_ids=inputs['token_type_ids'],labels=inputs['labels'])\n",
        "        test_loss = test_loss + loss.item()\n",
        "        _ , out_preds = torch.max(logits,axis=1)\n",
        "        test_acc =  test_acc + torch.eq(out_preds,inputs['labels'].squeeze(1)).sum().item()\n",
        "        preds_all.extend(out_preds.detach().cpu().numpy().tolist())\n",
        "        true_all.extend(inputs['labels'].squeeze(1).detach().cpu().numpy().tolist())\n",
        "\n",
        "      test_acc = test_acc / (len(test_data)*1.0)\n",
        "      tes_loss = test_loss / (1.0*len(test_loader))\n",
        "  return preds_all,true_all,test_loss,test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5svPrMqpEY90",
        "colab_type": "text"
      },
      "source": [
        "### Check Sequence Length for Choosing Seq Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPi2Cy4g_DGz",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "seq_len = []\n",
        "for i in range(len(train)):\n",
        "  text = train.iloc[i][\"text\"]\n",
        "  temp = tokenizer.encode_plus(text)\n",
        "  seq_len.append(len(temp[\"input_ids\"]))\n",
        "\n",
        "print(np.mean(seq_len))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY7L8xIDVfux",
        "colab_type": "text"
      },
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjq3NLuvV2JC",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XLNetClassifier(torch.nn.Module):\n",
        "  def __init__(self,labels):\n",
        "    super(XLNetClassifier,self).__init__()\n",
        "    #self.num_labels = labels\n",
        "    #self.config = config\n",
        "    self.xlnet_encoder = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',max_length=100,output_hidden_states=True,summary_type = \"mean\",_num_labels=labels)\n",
        "  \n",
        "  def forward(self,input_ids,token_type_ids,attention_mask,labels):\n",
        "    out = self.xlnet_encoder(input_ids=input_ids,token_type_ids=token_type_ids,\n",
        "                             attention_mask=attention_mask,labels=labels)\n",
        "    loss , logits = out[:2]\n",
        "    return (loss,logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM-iSJ5DNXKA",
        "colab_type": "text"
      },
      "source": [
        "## Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFUgmahadR8z",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  BATCH_SIZE = 16\n",
        "  LR = 2e-5\n",
        "  EPOCHS = 1\n",
        "  num_labels = len(Counter(train.target.values))\n",
        "  model = XLNetClassifier(num_labels)\n",
        "  #print(model.config)\n",
        "  model = train_engine(train,val,model.to(device),BATCH_SIZE,LR,EPOCHS,device)\n",
        "  model_best = XLNetClassifier(num_labels)\n",
        "  checkpoint = torch.load(\"/kaggle/saved_modelv1.pth\")\n",
        "  model_best.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "  model_best.to(device)\n",
        "  preds_all,true_all,test_loss,test_acc = test_engine(model_best,test)\n",
        "  target_name = list(le.classes_)\n",
        "  print(test_acc)\n",
        "  print(classification_report(true_all,preds_all,target_names=target_name))\n",
        "  pickle.dump(true_all,open(\"Test_True.p\",'wb'))\n",
        "  pickle.dump(preds_all,open(\"Test_Preds.p\",'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIYtJe4nOBp9",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsylITu1FN63",
        "outputId": "f41bc0fd-c183-4660-c475-b0df2ace61c5",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9913181478715459\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         Agent       1.00      0.99      0.99     44336\n",
            "        Device       0.96      1.00      0.98        88\n",
            "         Event       0.98      1.00      0.99      6765\n",
            "         Place       0.99      0.99      0.99     16282\n",
            "       Species       1.00      1.00      1.00      7787\n",
            "  SportsSeason       0.96      1.00      0.98      2077\n",
            "TopicalConcept       0.96      0.97      0.96       279\n",
            "    UnitOfWork       1.00      1.00      1.00       624\n",
            "          Work       0.99      0.99      0.99      7458\n",
            "\n",
            "      accuracy                           0.99     85696\n",
            "     macro avg       0.98      0.99      0.99     85696\n",
            "  weighted avg       0.99      0.99      0.99     85696\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY2PAXRCOwzo",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9hIN9avOCcy",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some Basic Tests\n",
        "z = torch.tensor([[1,4],[3,7],[2,5]])\n",
        "z1 = torch.tensor([1,1,0])\n",
        "z = z.to(device)\n",
        "_ , preds = torch.max(z,axis=1)\n",
        "print(z)\n",
        "print(preds)\n",
        "print(preds.detach().cpu())\n",
        "print(preds)\n",
        "torch.eq(preds,z1.to(device)).sum().item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPsEu_ESJgU0",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "1 2.218397746202519 1.7787151649263537 0.11122064440159676 2.2414355885923207 0.2325870646766169 0.05242849427672362"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo7jU9r8UmX6",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = XLNetConfig()\n",
        "config.from_pretrained = 'xlnet-base-cased'\n",
        "config.output_hidden_states = True\n",
        "config.output_attentions = False\n",
        "config.summary_type = 'mean'\n",
        "#config.n_layer = 12\n",
        "#config.n_head = 8\n",
        "config._num_labels = len(Counter(train.target.values))\n",
        "model = XLNetClassifier()\n",
        "model.xlnet_encoder.config.output_hidden_states = True\n",
        "model.xlnet_encoder.config.summary_type = \"mean\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lZ4dfaaUneN",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLn46dLRFTE4",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Input_ids = tokenizer.encode_plus(\"Hello, my dog is cute\", add_special_tokens=True)  # Batch size 1\n",
        "input_ids , atten_mask , token_type_ids, labels  = torch.tensor(Input_ids[\"input_ids\"]).unsqueeze(0), torch.tensor(Input_ids[\"attention_mask\"]).unsqueeze(0),torch.tensor(Input_ids[\"token_type_ids\"]).unsqueeze(0),torch.tensor([1]).unsqueeze(0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viIqDZfv7Nj7",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = model(input_ids=input_ids,attention_mask=atten_mask,token_type_ids=token_type_ids,labels=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L-5dRvU7fRB",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for z in model.xlnet_encoder.modules():\n",
        "  print(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1KEweE48L_z",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1= torch.tensor([0,1,3,2])\n",
        "t2 = torch.tensor([1,0,3,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBJ2xv9k8Oxo",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t2 = t2.view(4,-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSqkLxjeIirV",
        "outputId": "a9d5c141-e685-45d4-c42c-af02ab46c843",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WZhXoAH7gFcy",
        "colab_type": "code",
        "colab": {},
        "outputId": "1e4b1323-b998-47dd-c4ab-92aa963e4881"
      },
      "source": [
        "torch.eq(t1,t2.squeeze(1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fE9IMKLJNPZ",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = CreateData(tokenizer,val)\n",
        "val_loader = DataLoader(val_dataset,batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DJFiL4efaaC",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(torch.tensor([0,1,1,0,1],dtype=torch.long).sum()/5.0).item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYjahy4BffFU",
        "trusted": false,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}